{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227b9003",
   "metadata": {},
   "source": [
    "### Library imports and initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e8e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d74513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths in the project\n",
    "\n",
    "# Base Folder:\n",
    "base_folder = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Answers path\n",
    "answers_path = os.path.join(base_folder, 'Answers')\n",
    "\n",
    "# Vector_DBs path\n",
    "vector_dbs_path = os.path.join(base_folder, 'Vector_DBs')\n",
    "\n",
    "# Code path\n",
    "code_path = os.path.join(base_folder, 'Code')\n",
    "\n",
    "# AI_Prepositions path\n",
    "ai_prepositions_path = os.path.join(base_folder, 'AI_Prepositions')\n",
    "\n",
    "# Corpus path\n",
    "corpus_path = os.path.join(base_folder, 'Corpus')\n",
    "\n",
    "# Ground_Truth path\n",
    "ground_truth_path = os.path.join(base_folder, 'Ground_Truth')\n",
    "\n",
    "# RAGAS_Results path\n",
    "ragas_results_path = os.path.join(base_folder, 'RAGAS_Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c47b9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector store...\n"
     ]
    }
   ],
   "source": [
    "############### Only for vector_ia_db ####################\n",
    "# Add the Vector_DBs folder to the path\n",
    "sys.path.append(vector_dbs_path)\n",
    "from vector_ia_db import init_retriever\n",
    "retriever = init_retriever(force_recreate=False) \n",
    "\n",
    "############### Other vector DBs ####################\n",
    "# If we are using other vector DBs (not vector_ia_db) we need to export the code as follows:\n",
    "# sys.path.append(vector_dbs_path)\n",
    "# from Vector_768_50 import retriever  # Change the name according to the file you are going to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27214d76",
   "metadata": {},
   "source": [
    "### Select the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "324e0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = OllamaLLM(model = \"mistral:7b-instruct-v0.2-q8_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee109c",
   "metadata": {},
   "source": [
    "### Define the teamplate for the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b53790aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful, friendly, and knowledgeable AI assistant designed to support future international students of **NOVA IMS** – a leading school of Information Management and Data Science in Lisbon, Portugal.\n",
    "\n",
    "Your job is to provide accurate, encouraging, and easy-to-understand answers related to:\n",
    "- NOVA IMS Master’s and Postgraduate programs,\n",
    "- Portuguese Student VISA application requirements,\n",
    "- How to obtain residency after arriving in Portugal,\n",
    "- Finding housing and understanding living costs in Lisbon,\n",
    "- Other first steps for settling into life as a new international student in Lisbon.\n",
    "\n",
    "Use the following retrieved documents to provide accurate and relevant responses. You should **not mention document names, document IDs, or file references** — focus only on delivering a helpful and human response to the user.\n",
    "\n",
    "Your answers should be:\n",
    "- **Natural and conversational** — avoid sounding like you're quoting a file\n",
    "- **Clear and informative** — explain concepts simply and accurately\n",
    "- **Supportive and empathetic** — acknowledge that moving abroad is a big and exciting step\n",
    "\n",
    "Avoid technical language or internal references. Your goal is to make international students feel informed, confident, and supported.\n",
    "\n",
    "---\n",
    "If the user’s question is **not related to NOVA IMS, studying in Portugal, or moving to Lisbon as a student**, respond with:\n",
    "*\"I'm here to assist with questions about NOVA IMS, sturdent life in Potugal, and related topics — let me know how I can help!\"*\n",
    "\n",
    "If the user’s question **is relevant** but **cannot be answered from the provided documents**, say:\n",
    "*\"That’s an important question! Although I don’t have that information at the moment, I recommend reaching out to NOVA IMS directly or consulting the appropriate service for the most accurate and up-to-date details.\"*\n",
    "\n",
    "---\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "user: {question}\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f37face9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat prompt template using the previous template\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Create a processing chain by combining the prompt template with the model\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb0771a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "\n",
      " Hello there! I'm here to assist with questions about NOVA IMS, student life in Portugal, and related topics. If you have any specific queries about the university, its programs, or moving to Lisbon as an international student, feel free to ask! For instance, I can help answer questions about NOVA IMS faculty members, academic roles, application timelines, and more. Let me know how I can help!\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "\n",
      " The average monthly rent in Lisbon varies depending on the type of accommodation you're looking for. For a private room, it's around €490. A studio apartment typically costs around €1,056 per month, and an apartment will set you back about €1,750 on average. Keep in mind that these prices can change, so it's always a good idea to do some research or contact local housing providers for the most current information. I hope this helps, and remember, moving abroad is an exciting step! Let me know if there's anything else related to NOVA IMS, student life in Portugal, or Lisbon that I can help you with.\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List to store the relevante data of the interaction between the user and chatbot\n",
    "dataset = []\n",
    "\n",
    "while True:\n",
    "    print(\"\\n\\n-------------------------------------\")\n",
    "    question = input(\"Ask your question (q to quit): \")\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    if question.lower() == \"q\":\n",
    "        break\n",
    "\n",
    "    # Obtain the context\n",
    "    information = retriever.invoke(question)\n",
    "\n",
    "    # Get the answer\n",
    "    result = chain.invoke({\"context\": information, \"question\": question})\n",
    "\n",
    "    # Display the answer\n",
    "    print(result)\n",
    "\n",
    "    # Store it in the dataset\n",
    "    dataset.append({\n",
    "        \"question\": question,\n",
    "        \"answer\": result,\n",
    "        \"contexts\": information\n",
    "    })\n",
    "\n",
    "# This code was the first attemp to interact with the system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a66eb",
   "metadata": {},
   "source": [
    "### Function to obtain the necessary data to use RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3174b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_questions(questions, retriever, chain):\n",
    "    \"\"\"\n",
    "    Process a list of questions through the RAG pipeline.\n",
    "    \n",
    "    Args:\n",
    "        questions (list): List of questions to process\n",
    "        retriever: Document retriever object for finding relevant context\n",
    "        chain: LangChain processing chain for generating answers\n",
    "    \n",
    "    Returns:\n",
    "        list: Dataset containing questions, answers, and retrieved contexts\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for question in questions:\n",
    "        # Obtaining retriever documents\n",
    "        retrieved_docs = retriever.invoke(question)\n",
    "\n",
    "        # Extract text from each document\n",
    "        if isinstance(retrieved_docs, list):\n",
    "            context = [doc.page_content if hasattr(doc, \"page_content\") else str(doc) for doc in retrieved_docs]\n",
    "        else:\n",
    "            # Check if it is a list or not\n",
    "            context = [retrieved_docs.page_content] if hasattr(retrieved_docs, \"page_content\") else [str(retrieved_docs)]\n",
    "\n",
    "        # Obtain chain response\n",
    "        answer = chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "        # Store the interaction\n",
    "        dataset.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"contexts\": context\n",
    "        })\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = [\n",
    "    \"What is the average monthly rent in Lisbon?\", # 1\n",
    "    \"How much does transportation cost in Lisbon?\", # 2\n",
    "    \"What is the overall cost of living in Lisbon?\", # 3\n",
    "    \"What steps should I take after arriving in Lisbon?\", # 4\n",
    "    \"Does NOVA IMS accept international students?\", # 5\n",
    "    \"As a non-EU student, what are the requirements to study at NOVA IMS in Lisbon?\", # 6\n",
    "    \"What is the Portuguese Social Security Identification Number (NISS), and why do I need it?\", # 7\n",
    "    \"How can a foreign citizen obtain a NISS?\", # 8\n",
    "    \"How many master's programs does NOVA IMS offer?\", # 9\n",
    "    \"Can you provide a list of the master's programs available at NOVA IMS?\", # 10\n",
    "    \"Is there a master's program related to marketing?\", # 11\n",
    "    \"What information can you provide about the Master’s Degree in Data Science and Advanced Analytics, specializing in Business Analytics?\", # 12\n",
    "    \"Who is the coordinator of the Master’s Degree in Data Science and Advanced Analytics, specializing in Business Analytics?\", # 13\n",
    "    \"As a foreign student, how much does it cost to study for a Bachelor's Degree at NOVA IMS?\", # 14\n",
    "    \"What are the entry requirements for the Postgraduate Program in Enterprise Data Science & Analytics?\", # 15\n",
    "    \"How can I apply to the Postgraduate Program in Enterprise Data Science & Analytics?\", # 16\n",
    "    \"Are there any discounts available for the Master’s Degree in Information Management, specializing in Business Intelligence?\", # 17\n",
    "    \"Does Professor Fernando Bação coordinate any academic programs?\", # 18\n",
    "    \"Can I apply to multiple programs at NOVA IMS?\", # 19\n",
    "    \"Does NOVA IMS provide accommodation options?\", # 20\n",
    "    \"Can you recommend websites for finding accommodation in Lisbon?\", # 21\n",
    "    \"I’m interested in learning Portuguese. Does the university offer a Portuguese language course?\", # 22\n",
    "    \"I want to apply to three programs. Is that possible, and is there an application fee?\", # 23\n",
    "    \"As a higher education student, how can I obtain a residence permit in Portugal?\", # 24\n",
    "    \"What documents do I need to apply for a residence permit as a higher education student?\", # 25\n",
    "    \"How can I prove my financial means to qualify for a residence permit?\" # 26\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function using the questions_list\n",
    "result_dataset = process_questions(questions_list, retriever, chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the name according with the model you are using\n",
    "mistral_ai_dataset = result_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the results of the model\n",
    "dataset = mistral_ai_dataset\n",
    "\n",
    "# Save results\n",
    "with open(os.path.join(answers_path, \"mistral_ai_answers.json\"), \"w\", encoding=\"utf-8\") as f:  # Change the name according to the model and version\n",
    "    json.dump(dataset, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bb885d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(answers_path, \"mistral_ai_answers.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55127850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to merge the question, answer, and context with the ground truth\n",
    "\n",
    "# Import the .json file with the ground truth answers\n",
    "with open(os.path.join(ground_truth_path, \"Ground_truth_answers.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    Ground_truth = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd820c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the “ground_truth” key to the dictionary\n",
    "test = []\n",
    "for data_dict, x_dict in zip(dataset, Ground_truth):\n",
    "    data_dict[\"ground_truth\"] = x_dict[\"ground_truth\"]\n",
    "    test.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b81a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export .json file with ground truth\n",
    "with open(os.path.join(ground_truth_path, \"mistral_ai_truth.json\"), \"w\", encoding=\"utf-8\") as f:  # Change the name according to the model and version\n",
    "    json.dump(test, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
