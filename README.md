# Thesis_MDSAA

This repository contains the files used to build the chatbot prototype. Its structure is organized as follows:
1.	RAG/ (Base directory)
  a.	AI_Prepositions/: includes texts created using the AI-generated chunking method.
    i.	ai_chunk_process.json: Contains the generated chunks for each document, derived from ai_text_prepositions.json.
    ii.	ai_text_prepositions.json: Stores prepositions generated for each corpus document.
  b.	Answers/: Contains the retrieved answers (along with corresponding questions and context) for each model used in the project, formatted as .json files.
    i.	1 file for the llama.3.1. model
    ii.	1 file for the phi-4 model
    iii.	7 files for the mistral model, one per chunking method tested
  c.	Code/: Contains 6 scripts/notebooks used throughout the project:
    i.	Chunking_ia_process.ipynb is the file used to execute the AI-generated chunking method. It uses the AI_chunker_v2.py to call the necessary functions. It processes .txt files from the Corpus/ folder and generates .json outputs in AI_Prepositions/.
    ii.	Chatbot.py: Deploys the chatbot prototype using Streamlit. Currently configured to use vector_ia_db.py, referencing the vector database created with the AI-generated chunks.
    iii.	RAG.ipynb: Executes the RAG pipeline with a set of questions, storing the answers and retrieved context for model evaluation via RAGAS.
    iv.	RAGAS â€“ Azure.ipynb: Applies the RAGAS framework using metrics such as answer_relevancy, context_precision, context_recall, faithfulness. Outputs scores to .xlsx files stored in RAGAS_Results/.
  d.	Corpus/: Contains all raw .txt files used to build the corpus.
  e.	Ground_Truth/: Stores the ground truth answers:
    i.	Ground_truth_answers.json: Original ground truth. 
    ii.	Additional files merge results (Answers/) from each model with the original ground truth file to support RAGAS evaluation.
  f.	RAGAS_Results/: Includes RAGAS evaluation scores generated by RAGAS_Azure.ipynb, organized per model and approach.
  g.	Vector_DBs/: Contains scripts that generate vector databases. ue to GitHub size limits, these must be run locally to recreate the vector DBs.


Notes:
1.	Before running Chatbot.py, ensure that the chrome_db_ia vector database has been created by executing the vector_ia_db.py script.
2.	Ollama must be running in the background, with both the required LLM and embedding model already downloaded.
3.	To fully execute certain scripts, Azure API credentials must be properly configured.
