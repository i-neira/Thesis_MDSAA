# Thesis_MDSAA

This repository contains the files used to build the chatbot prototype. Its structure is organized as follows:

1. **RAG/** (Base directory)  
   a. **AI_Prepositions/**: includes texts created using the AI-generated chunking method.  
   &nbsp;&nbsp;&nbsp;&nbsp;i. `ai_chunk_process.json`: Contains the generated chunks for each document, derived from `ai_text_prepositions.json`.  
   &nbsp;&nbsp;&nbsp;&nbsp;ii. `ai_text_prepositions.json`: Stores prepositions generated for each corpus document.  

   b. **Answers/**: Contains the retrieved answers (along with corresponding questions and context) for each model used in the project, formatted as `.json` files.  
   &nbsp;&nbsp;&nbsp;&nbsp;i. 1 file for the **llama.3.1.** model  
   &nbsp;&nbsp;&nbsp;&nbsp;ii. 1 file for the **phi-4** model  
   &nbsp;&nbsp;&nbsp;&nbsp;iii. 7 files for the **mistral** model, one per chunking method tested  

   c. **Code/**: Contains 6 scripts/notebooks used throughout the project:  
   &nbsp;&nbsp;&nbsp;&nbsp;i. `Chunking_ia_process.ipynb` is the file used to execute the AI-generated chunking method. It uses the `AI_chunker_v2.py` to call the necessary functions. It processes `.txt` files from the **Corpus/** folder and generates `.json` outputs in **AI_Prepositions/**.  
   &nbsp;&nbsp;&nbsp;&nbsp;ii. `Chatbot.py`: Deploys the chatbot prototype using Streamlit. Currently configured to use `vector_ia_db.py`, referencing the vector database created with the AI-generated chunks.  
   &nbsp;&nbsp;&nbsp;&nbsp;iii. `RAG.ipynb`: Executes the RAG pipeline with a set of questions, storing the answers and retrieved context for model evaluation via RAGAS.  
   &nbsp;&nbsp;&nbsp;&nbsp;iv. `RAGAS â€“ Azure.ipynb`: Applies the RAGAS framework using metrics such as `answer_relevancy`, `context_precision`, `context_recall`, `faithfulness`. Outputs scores to `.xlsx` files stored in **RAGAS_Results/**.  

   d. **Corpus/**: Contains all raw `.txt` files used to build the corpus.  

   e. **Ground_Truth/**: Stores the ground truth answers:  
   &nbsp;&nbsp;&nbsp;&nbsp;i. `Ground_truth_answers.json`: Original ground truth.  
   &nbsp;&nbsp;&nbsp;&nbsp;ii. Additional files merge results (**Answers/**) from each model with the original ground truth file to support RAGAS evaluation.  

   f. **RAGAS_Results/**: Includes RAGAS evaluation scores generated by `RAGAS_Azure.ipynb`, organized per model and approach.  

   g. **Vector_DBs/**: Contains scripts that generate vector databases. Due to GitHub size limits, these must be run locally to recreate the vector DBs.  

---

### Notes:
1. Before running `Chatbot.py`, ensure that the `chrome_db_ia` vector database has been created by executing the `vector_ia_db.py` script.  
2. Ollama must be running in the background, with both the required LLM and embedding model already downloaded.  
3. To fully execute certain scripts, Azure API credentials must be properly configured.
